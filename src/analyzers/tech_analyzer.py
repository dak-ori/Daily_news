"""
ê¸°ìˆ  ë¶„ì„ê¸°
LLMì„ ì‚¬ìš©í•˜ì—¬ ê¸°ìˆ /ì €ì¥ì†Œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
"""
import json
from typing import Dict, Any, List, Optional
import logging
from .llm_client import LLMClient
from ..scrapers.models import TrendingRepository
from ..database.supabase_client import SupabaseClient

logger = logging.getLogger(__name__)


class TechAnalyzer:
    """ê¸°ìˆ  ë¶„ì„ê¸°"""

    def __init__(self, provider: str = "openai", use_cache: bool = True):
        self.llm = LLMClient(provider=provider)
        self.use_cache = use_cache
        self._db = None
    
    @property
    def db(self) -> SupabaseClient:
        """ì§€ì—° ì´ˆê¸°í™”ëœ DB í´ë¼ì´ì–¸íŠ¸"""
        if self._db is None:
            try:
                self._db = SupabaseClient()
            except Exception as e:
                logger.warning(f"DB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨, ìºì‹± ë¹„í™œì„±í™”: {e}")
                self.use_cache = False
        return self._db

    def analyze_repository(
        self, repo: TrendingRepository, skip_cache: bool = False
    ) -> Dict[str, Any]:
        """
        GitHub ì €ì¥ì†Œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.

        Args:
            repo: TrendingRepository ê°ì²´
            skip_cache: ìºì‹œ ë¬´ì‹œ ì—¬ë¶€

        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # ìºì‹œ í™•ì¸
            if self.use_cache and not skip_cache:
                cached = self._get_cached_analysis(repo.name)
                if cached:
                    logger.info(f"âœ… ìºì‹œ ì‚¬ìš©: {repo.name}")
                    return cached
            
            logger.info(f"ğŸ”„ ì €ì¥ì†Œ ë¶„ì„ ì‹œì‘: {repo.name}")

            prompt = self._create_analysis_prompt(repo)
            system_prompt = "ë‹¹ì‹ ì€ ê¸°ìˆ  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. GitHub ì €ì¥ì†Œë¥¼ ë¶„ì„í•˜ê³  í•œêµ­ì–´ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”."

            response = self.llm.generate(prompt, system_prompt)

            # JSON íŒŒì‹±
            analysis = self._parse_analysis_response(response)

            logger.info(f"âœ… ì €ì¥ì†Œ ë¶„ì„ ì™„ë£Œ: {repo.name}")
            return analysis

        except Exception as e:
            logger.error(f"ì €ì¥ì†Œ ë¶„ì„ ì‹¤íŒ¨: {repo.name} - {e}")
            return {}
    
    def _get_cached_analysis(self, repo_name: str) -> Optional[Dict[str, Any]]:
        """ìºì‹œëœ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ"""
        if not self.use_cache or self.db is None:
            return None
        
        try:
            cached = self.db.get_cached_ai_analysis(repo_name)
            if cached and cached.get("ai_summary"):
                return cached
        except Exception as e:
            logger.warning(f"ìºì‹œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None

    def _create_analysis_prompt(self, repo: TrendingRepository) -> str:
        """ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        prompt = f"""
ë‹¤ìŒ GitHub ì €ì¥ì†Œì— ëŒ€í•´ ë¶„ì„í•´ì£¼ì„¸ìš”.

ì €ì¥ì†Œ: {repo.name}
ì„¤ëª…: {repo.description or "ì„¤ëª… ì—†ìŒ"}
ì–¸ì–´: {repo.language or "ì•Œ ìˆ˜ ì—†ìŒ"}
Stars: {repo.stars:,}
ì˜¤ëŠ˜ ì¦ê°€í•œ Stars: {repo.stars_today}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:

{{
  "what_is_it": "ì´ ê¸°ìˆ /ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ë¬´ì—‡ì¸ì§€ 2-3ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…",
  "key_features": ["íŠ¹ì§•1", "íŠ¹ì§•2", "íŠ¹ì§•3"],
  "use_cases": ["ì‹¤ë¬´ í™œìš© ì‚¬ë¡€1", "í™œìš© ì‚¬ë¡€2", "í™œìš© ì‚¬ë¡€3"],
  "difficulty": "ì´ˆê¸‰|ì¤‘ê¸‰|ê³ ê¸‰",
  "related_stack": ["ê´€ë ¨ê¸°ìˆ 1", "ê´€ë ¨ê¸°ìˆ 2", "ê´€ë ¨ê¸°ìˆ 3"]
}}

JSONë§Œ ë°˜í™˜í•˜ê³  ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
"""
        return prompt

    def _parse_analysis_response(self, response: str) -> Dict[str, Any]:
        """LLM ì‘ë‹µ íŒŒì‹±"""
        try:
            # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
            response = response.strip()

            # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
            if response.startswith("```"):
                response = response.split("```")[1]
                if response.startswith("json"):
                    response = response[4:]

            # JSON íŒŒì‹±
            data = json.loads(response)

            return {
                "ai_summary": data.get("what_is_it", ""),
                "ai_use_cases": data.get("use_cases", []),
                "ai_difficulty": data.get("difficulty", "ì¤‘ê¸‰"),
                "ai_related_tech": data.get("related_stack", []),
            }

        except json.JSONDecodeError as e:
            logger.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return {}

    def analyze_daily_trends(
        self, repos: List[TrendingRepository], articles: List[Any]
    ) -> Dict[str, Any]:
        """
        ì¼ì¼ íŠ¸ë Œë“œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.

        Args:
            repos: íŠ¸ë Œë”© ì €ì¥ì†Œ ëª©ë¡
            articles: ë‰´ìŠ¤ ê¸°ì‚¬ ëª©ë¡

        Returns:
            ì¼ì¼ íŠ¸ë Œë“œ ë¶„ì„ ê²°ê³¼
        """
        try:
            logger.info("ì¼ì¼ íŠ¸ë Œë“œ ë¶„ì„ ì‹œì‘")

            prompt = self._create_daily_summary_prompt(repos, articles)
            system_prompt = "ë‹¹ì‹ ì€ ê¸°ìˆ  íŠ¸ë Œë“œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì˜¤ëŠ˜ì˜ ê¸°ìˆ  íŠ¸ë Œë“œë¥¼ í•œêµ­ì–´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”."

            response = self.llm.generate(prompt, system_prompt, max_tokens=1500)

            # JSON íŒŒì‹±
            analysis = self._parse_daily_summary(response)

            logger.info("ì¼ì¼ íŠ¸ë Œë“œ ë¶„ì„ ì™„ë£Œ")
            return analysis

        except Exception as e:
            logger.error(f"ì¼ì¼ íŠ¸ë Œë“œ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}

    def _create_daily_summary_prompt(
        self, repos: List[TrendingRepository], articles: List[Any]
    ) -> str:
        """ì¼ì¼ ìš”ì•½ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        # ìƒìœ„ 10ê°œ ì €ì¥ì†Œ
        top_repos = repos[:10]
        repo_list = "\n".join(
            [
                f"- {repo.name} ({repo.language}): {repo.description or 'ì„¤ëª… ì—†ìŒ'} - â­{repo.stars:,} (+{repo.stars_today})"
                for repo in top_repos
            ]
        )

        # ìƒìœ„ 5ê°œ ë‰´ìŠ¤
        top_articles = articles[:5]
        article_list = "\n".join(
            [f"- {article.title} ({article.source})" for article in top_articles]
        )

        prompt = f"""
ì˜¤ëŠ˜ì˜ GitHub Trending ì €ì¥ì†Œì™€ IT ë‰´ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê¸°ìˆ  íŠ¸ë Œë“œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

## GitHub Trending (ìƒìœ„ 10ê°œ)
{repo_list}

## IT ë‰´ìŠ¤ (ìƒìœ„ 5ê°œ)
{article_list}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:

{{
  "daily_summary": "ì˜¤ëŠ˜ì˜ ê¸°ìˆ  íŠ¸ë Œë“œë¥¼ 3-4ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½",
  "hot_technologies": [
    {{"name": "ê¸°ìˆ ëª…1", "description": "ì„¤ëª…", "why_hot": "ì£¼ëª©ë°›ëŠ” ì´ìœ "}},
    {{"name": "ê¸°ìˆ ëª…2", "description": "ì„¤ëª…", "why_hot": "ì£¼ëª©ë°›ëŠ” ì´ìœ "}}
  ],
  "learning_recommendations": ["ë°°ì›Œë³¼ ë§Œí•œ ê¸°ìˆ 1", "ë°°ì›Œë³¼ ë§Œí•œ ê¸°ìˆ 2"]
}}

JSONë§Œ ë°˜í™˜í•˜ê³  ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
"""
        return prompt

    def _parse_daily_summary(self, response: str) -> Dict[str, Any]:
        """ì¼ì¼ ìš”ì•½ ì‘ë‹µ íŒŒì‹±"""
        try:
            # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
            response = response.strip()

            if response.startswith("```"):
                response = response.split("```")[1]
                if response.startswith("json"):
                    response = response[4:]

            data = json.loads(response)

            return {
                "ai_daily_summary": data.get("daily_summary", ""),
                "ai_hot_technologies": data.get("hot_technologies", []),
                "ai_learning_recommendations": data.get("learning_recommendations", []),
            }

        except json.JSONDecodeError as e:
            logger.error(f"ì¼ì¼ ìš”ì•½ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return {}

    def summarize_article(self, article) -> str:
        """
        ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ AIë¡œ ìš”ì•½í•©ë‹ˆë‹¤.
        
        Args:
            article: NewsArticle ê°ì²´
            
        Returns:
            ìš”ì•½ëœ ë¬¸ìì—´
        """
        try:
            # ì´ë¯¸ ìš”ì•½ì´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
            if article.summary and len(article.summary) > 50:
                return article.summary
            
            prompt = f"""
ë‹¤ìŒ IT ë‰´ìŠ¤ ê¸°ì‚¬ ì œëª©ì„ ë³´ê³  í•œêµ­ì–´ë¡œ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš” (1-2ë¬¸ì¥):

ì œëª©: {article.title}
ì¶œì²˜: {article.source}

ì´ ê¸°ì‚¬ê°€ ì–´ë–¤ ë‚´ìš©ì¼ì§€ ì œëª©ì„ ë°”íƒ•ìœ¼ë¡œ ì¶”ì¸¡í•´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
ì„¤ëª…ë§Œ ì‘ì„±í•˜ê³  ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
"""
            system_prompt = "ë‹¹ì‹ ì€ IT ë‰´ìŠ¤ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê¸°ì‚¬ ì œëª©ì„ ë³´ê³  ê°„ê²°í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
            
            summary = self.llm.generate(prompt, system_prompt, max_tokens=150)
            return summary.strip()
            
        except Exception as e:
            logger.error(f"ê¸°ì‚¬ ìš”ì•½ ì‹¤íŒ¨: {article.title} - {e}")
            return ""

    def summarize_articles(self, articles: List, max_articles: int = 10) -> List:
        """
        ì—¬ëŸ¬ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤.
        
        Args:
            articles: NewsArticle ë¦¬ìŠ¤íŠ¸
            max_articles: ìµœëŒ€ ìš”ì•½í•  ê¸°ì‚¬ ìˆ˜
            
        Returns:
            ìš”ì•½ì´ ì¶”ê°€ëœ NewsArticle ë¦¬ìŠ¤íŠ¸
        """
        logger.info(f"ğŸ“° ë‰´ìŠ¤ ê¸°ì‚¬ AI ìš”ì•½ ì‹œì‘ (ìµœëŒ€ {max_articles}ê°œ)")
        
        for i, article in enumerate(articles[:max_articles]):
            if not article.summary or len(article.summary) < 50:
                summary = self.summarize_article(article)
                if summary:
                    article.summary = summary
                    logger.info(f"  âœ… [{i+1}/{min(len(articles), max_articles)}] {article.title[:30]}...")
        
        return articles
